## 散列表

许多应用都需要一种动态集合结构，它至少需要支持 insert、search 和 delete 操作。散列表 (hash table) 是实现字典操作的一种有效的数据结构。尽管在最坏情况下，散列表中查找一个元素的时间与链表中查找的时间相同，达到了 Θ(n)，然而在实际应用中，散列查找的性能是极好的。在一些合理的假设下，在散列表中查找一个元素的平均时间是 O(1)。

散列表是普通数组概念的推广。对于普通数组可以直接寻址，使得能在 O(1) 时间内访问数组中的任意位置。如果存储空间允许，我们可以提供一个数组，为每个可能的关键字保留一个位置，以利用直接寻址技术的优势。

当实际存储的关键字数目比全部的可能关键字总数要小时，采用散列表就成为直接数组寻址的一种有效替代，因为散列表采用一个长度与实际存储的关键字数目成比例的数组来存储。在散列表中，不是直接把关键字作为数组的下标，而是根据关键字计算出相应的下标。

散列是一种极其有效和实用的技术，基本的字典操作平均只需要 O(1) 时间，当关键字集合是静态存储（即关键字集合一旦存入后就不再改变）时，完全散列 (perfect hashing) 能够在 O(1) 的最坏时间内完成关键字查找。

### 直接寻址表

当关键字的全域 U 比较小时，直接寻址是一种简单而有效的技术。假设某应用要用到一个动态集合，其中每个元素都是取自于全域 U = {0, 1, 2, ..., m - 1} 中的一个关键字，这里 m 不是一个很大的数。另外，假设没有两个元素具有相同的关键字。

为表示动态集合，我们用一个数组，或称为直接寻址表 (direct-address table)，记为 T[0...m-1]。其中每个位置称为槽 (slot)，对应全域 U 中的一个关键字。

直接寻址表的缺点是非常明显的：如果全域 U 很大，则在一台标准的计算机可用内存容量中，要存储大小为 U 的一张表 T 也许不太实际，甚至是不可能的。还有，实际存储的关键字集合 K 相对 U 来说可能很小，使得分配给 T 的大部分空间都将浪费掉。

当存储在字典中的关键字集合 K 比所有可能的关键字的全域 U 要小许多时，散列表需要的存储空间要比直接寻址表少得多。特别地，我们能将散列表的存储需求降至 Θ(K)，同时散列表中查找一个元素的优势仍得到保持，只需要 O(1) 的时间。问题是这个界是针对平均情况时间的，而对直接寻址来说，它是适用于最坏情况时间的。

在直接寻址方式下，具有关键字 k 的元素被存放在槽 k 中，在散列方式下，该元素存放在槽 h(k)中，即利用散列函数 (hash function) h，由关键字计算出槽的位置。我们可以说一个具有关键字 k 的元素被散列到槽 h(k)上，也可以说 h(k) 是关键字 k 的散列值。散列函数缩小了数组下标的范围，即减小了数组的大小，使其由 U 减小为 m。

这里存在一个问题：两个关键字可能映射到同一个槽中，我们称这种情形为冲突 (collision)。幸运的是，我们能找到有效的方法来解决冲突。

当然，理想的解决办法是避免所有的冲突。我们可以试图选择一个合适的散列函数h来做到这一点，一个想法就是使 h 尽可能的随机，从而避免冲突或使冲突的次数最小化。实际上，术语“散列”的原意就是随机混杂和拼凑，即体现了这种思想。当然，一个散列函数 h 必须是确定的，因为某一个给定的输入k应始终产生相同的结果 h(k)。但是，由于 U > m，故至少有两个关键字其散列值相同，所以要完全避免冲突是不可能的。因此，我们一方面可以通过精心设计的散列函数来尽量减少冲突的次数，另一方面，仍需要有解决可能出现冲突的办法。

### 通过链接法解决冲突

在链接法中，把散列到同一槽中的所有关键字都放在一个链表中。

### 散列函数

#### 好的散列函数的特点

一个好的散列函数应（近似地）满足简单均匀散列假设：每个关键字都被等可能地散列到 m 个槽位中的任何一个，并与其他关键字已散列到哪个槽位无关。

#### 除法散列法

在用来设计散列函数的除法散列法中，通过取 k 除以 m 的余数，将关键字 k 映射到 m 个槽中的某一个上，即散列函数为：

h(k) = k mod m

例如，假如散列表的大小为 m = 12，所给关键字 k = 100，则 h(k) = 4。由于只需做一次除法操作，所以除法散列是非常快的。

当应用除法散列法时，要避免选择 m 的某些值。例如，m 不应为 2 的幂，因为如果 m = 2 ^ p，则 h(k) 就是 k 的 p 个最低位数字。除非已知各种最低 p 位的排列形式为等可能的，否则在设计散列函数时，最好考虑关键字的所有位。一个不太接近 2 的整数幂的素数，通常是 m 的一个较好的选择。

#### 乘法散列法

构造散列函数的乘法散列法包含两个步骤。第一步，用关键字k乘上常数 A(0 < A < 1)，并提取 kA 的小数部分。第二步，用 m 乘以这个值，再向下取整。总之，散列函数为：

h(k) = Math.floor(m * (k * A mod 1))

这里 k & A mod 1 是取 k * A 的小数部分，即 k * A - Math.floor(k * A)。

乘法散列法的一个优点是对 m 的选择不是特别关键，一般选择它为 2 的某个次幂 (m = 2 ^ p，p为某个整数)。

#### 全域散列法

如果让一个恶意的对手来针对某个特定的散列函数选择要散列的关键字，那么他会将 n 个关键字全部散列到同一个槽中，使得平均的检索时间为 Θ(n)。任何一个特定的散列函数都可能出现这种最坏情况。唯一有效的改进方法是随机地选择散列函数，使之独立于要存储的关键字。这种方法称为全域散列 (universal hashing)，不管对手选择了什么样的关键字，其平均性能都很好。

全域散列法在执行开始时，就从一组精心设计的函数中，随机地选择一个作为散列函数。就像在快速排序中一样，随机化保证了没有哪一种输入会始终导致最坏情况性能。因为随机地选择散列函数，算法在每一次执行时都会有所不同，甚至对于相同的输入都会如此。这样就可以确保对任何输入，算法都具有较好的平均性能。

设 H 为一组有限散列函数，它将给定的关键字全域 U 映射到 {0, 1, ..., m - 1} 中，这样的一个函数组称为全域 (universal) 的，如果对每一对不同的关键字 k，l∈U，满足 h(k) = h(l) 的散列函数 h 的个数至多为 H / m。换句话说，如果从 H 中随机选择一个散列函数，当关键字 k != l 时，两者发生冲突的概率不大于 1 / m，这也正好是从集合 {0, 1, ..., m - 1} 中独立地随机选择 h(k) 和 h(l) 时发生冲突的概率。

### 开放寻址法

在开放寻址法 (open addressing) 中，所有的元素都存放在散列表里。也就是说，每个表项或包含动态集合的一个元素，或包含 null。当查找某个元素时，要系统地检查所有的表项，直到找到所需的元素，或者最终查明该元素不在表中。不像链接法，这里既没有链表，也没有元素存放在散列表外，因此，在开放寻址法中，散列表可能会被填满，以至于不能插入任何新的元素。该方法导致的一个后果便是装载因子 a 绝对不会超过 1。

当然，也可以将用作链接的链表存放在散列表未用的槽中，但开放寻址法的好处就在于它不用指针，而是计算出要存取的槽序列。于是，不用存储指针而节省的空间，使得可以用同样的空间来提供更多的槽，潜在地减少了冲突，提高了检索速度。

为了使用开放寻址法插入一个元素，需要连续地检查散列表，或称为探查 (probe)，直到找到一个空槽来放置待插入的关键字为止。检查的顺序不一定是 0, 1, ..., m - 1，这种顺序下的查找时间为 Θ(n)，而是要依赖于待插入的关键字。为了确定要探查哪些槽，我们将散列函数加以扩充，使之包含探查号（从0开始）以作为其第二个输入参数，这样，散列函数就变为：

h: U x {0, 1, ..., m - 1} -> {0, 1, ..., m - 1}

对每一个关键字 k，使用开放寻址法的探查序列 (probe sequence) <h(k, 0), h(k, 1), h(k, 2), ..., h(k, m - 1)> 是 <0, 1, 2, ..., m - 1> 的一个排列，使得当散列表逐渐填满时，每一个表位最终都可以被考虑为用来插入新关键字的槽。

```java
public class HashTable {
    int m;
    Node[] nodes;
    
    class Node {
        int key;
        
        Node(int key) {
            this.key = key;
        }
    }
    
    HashTable(int capacity) {
        m = capacity;
        nodes = new Node[capacity];
    }
    
    int h(int key, int i) {
        return (h1(key) + i * h2(key)) % m;
    }

    int h1(int key) {
        return key % m;
    }

    int h2(int key) {
        return 1 + (key % (m - 1));
    }
    
    void insert(int key) {
        int i = 0;
        do {
            int j = h(key, i);
            if (nodes[j] == null) {
                nodes[j] = new Node(key);
                return;
            }
            i++;
        } while (i != m);
        throw new RuntimeException("hash table overflow");
    }
}
```

查找关键字 k 的算法的探查序列与将 k 插入时的算法一样，因此，查找过程中碰到一个空槽时，查找算法就（非成功地）停止，因为如果 k 在表中，它就应该在此处，而不会在探查序列随后的位置上（之所以这么说，是假定了关键字不会从散列表中删除）。

```
Node search(int key) {
    int i = 0;
    int j;
    do {
        j = h(key, i);
        if (nodes[j].key == key) {
            return nodes[j];
        }
        i++;
    } while (nodes[j] != null && i != m);
    return null;
}
```

从开放寻址法的散列表中删除元素比较困难。当我们从槽 i 中删除关键字时，不能仅将 null 置于其中来标识它为空。如果这样做，就会有问题：在插入关键字 k 时，发现槽 i 被占用了，则 k 就被插入到后面的位置上，此时将槽 i 中的关键字删除后，就无法检索到关键字 k 了。有一个解决办法，就是在槽i中置一个特定的值 DELETED 替代 null 来标记该槽。这样就要对 insert 做相应的修改，将这样的一个槽当做空槽，使得在此仍然可以插入新的关键字。对 search 无需做什么改动，因为它在搜索时会绕过 DELETED 标识。但是我们使用特殊的值 DELETED 时，查找时间就不再依赖于装载因子 a 了。为此，在必须删除关键字的应用中，更常见的做法是采用链接法来解决冲突。

在我们的分析中，做一个均匀散列 (uniform hashing) 的假设：每个关键字的探查序列等可能地为 <0, 1, ..., m - 1> 的 m! 种排列中的任意一种。均匀散列将前面定义过的简单均匀散列的概念加以了一般化，推广到散列函数的结果不只是一个数，而是一个完整的探查序列。然而，真正的均匀散列是难以实现的，在实际应用中，常常采用它的一些近似方法，如双重散列等。

有三种技术常用来计算开放寻址法中的探查序列：线性探查、二次探查和双重探查。这几种技术都能保证对每个关键字 k，<h(k, 0), h(k, 1), ..., h(k, m - 1)> 都是 <0, 1, ..., m - 1> 的一个排列。但是，这些技术都不能满足均匀散列的假设，因为它们能产生的不同探查序列数都不超过 m ^ 3 个（均匀散列要求有 m! 个探查序列）。三种技术中，双重散列产生的探查序列数最多，似乎能给出最好的结果。

#### 线性探查

给定一个普通的散列函数 h': U -> {0, 1, ..., m - 1}，称之为辅助散列函数 (auxiliary hash function)，线性探查 (linear probing) 方法采用的散列函数为：

h(k, i) = (h'(k) + i) mod m,          i = 0, 1, ..., m - 1

给定一个关键字 k ，首先探查槽 T[h'(k)]，即由辅助函数所给出的槽位，再探查槽 T[h'(k) + 1]，以此类推，直至槽 T[m - 1]。然后，又绕到槽 T[0], T[1] ..., 直到最后探查到槽 T[h'(k) - 1]。在线性探查方法中，初始探查位置决定了整个序列，故只有 m 种不同的探查序列。

线性探查方法比较容易实现，但它存在一个问题，称为一次集群现象 (primary clustering)。随着连续被占用的槽不断增加，平均查找时间也随之不断增加。集群现象很容易出现，这是因为一个空槽前有 i 个满的槽时，该空槽为下一个即将被占用的概率是 (i + 1) / m。连续被占用的槽就会变得越来越长，因而平均查找时间也会越来越长。

#### 二次探查

二次探查 (quadratic probing) 采用如下形式的散列函数：

h(k, i) = (h'(k) + c1 * i + c2 * (i ^ 2)) mod m

其中 h' 是一个辅助函数，c1 和 c2 为正的辅助常数，i = 0, 1, ..., m - 1。初始的探查位置为 T[h'(k)]，后续的探查位置要加上一个偏移量，该偏移量以二次的方式依赖于探查序号 i。这种探查方法的效果要比线性探查好得多，但是，为了能够充分利用散列表，c1、c2 和 m 的值要受到限制。此外，如果两个关键字的初始探查位置相同，那么它们的探查序列也是相同的，这是因为 h(k1, 0) == h(k2, 0) 蕴含着 h(k1, i) == h(k2, i)。这一性质可导致一种轻度的集群，称为二次集群 (secondary clustering)。就像在线性探查中一样，初始探查位置决定了整个序列，这样也仅有 m 个不同的探查序列被用到。

#### 双重散列

双重散列 (double hashing) 是用于开放寻址法的最好方法之一，因为它所产生的排列具有随机选择排列的许多特性。双重散列采用如下形式的散列函数：

h(k, i) = (h1(k) + i * h2(k)) mod m

其中 h1 和 h2 均为辅助散列函数。初始探查位置为 T[h1(k)]，后续的探查位置是前一个位置加上偏移量 h2(k) 模 m。因此，不像线性探查或二次探查，这里的探查序列以两种不同的方式依赖于关键字 k，因为初始探查位置、偏移量或者二者都可能发生变化。
